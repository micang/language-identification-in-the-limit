% ----- new page ---
INFORMATION AND CONTROL 10, 447474 '(1967)

Language Identiﬁcation in the Limit

E MARK GOLD*

The RAND Corporation

Language learnability has been investigated. This refers to the fol-
lowing situation: A class of possible languages is speciﬁed, together
with a method of presenting information to the learner about an un-
known language, which is to be chosen from the class. The question
is now asked, “Is the information sufﬁcient to determine which of the
possible languages is the unknown language?” Many deﬁnitions of
learnability are possible, but only the following is considered here:
Time is quantized and has a ﬁnite starting time. At each time the
learner receives a unit of information and is to make a guess as to the
identity of the unknown language on the basis of the information
received so far. This process continues forever. The class of languages
will be considered learnablc with respect to the speciﬁed method of
information presentation if there is an algorithm that the learner can
use to make his guesses, the algorithm having the following property:
Given any language of the class, there is some ﬁnite time after which
the guesses will all be the same and they will be correct.

In this preliminary investigation, a language is taken to be a set of
strings on some ﬁnite alphabet. The alphabet is the same for all lan-
guages of the class. Several variations of each of the following two
basic methods of information presentation are investigated: A text for
:1 language generates the strings of the language in any order such that
every string of the language occurs at least once. An informant for a
language tells whether a string is in the language, and chooses the
strings in some order such that every string occurs at least once.

It was found that the class of context—sensitive languages is learn-
able from an informant, but that not even the class of regular lan—
guages is learnable from a text.

1. MOTIVATION: TO SPEAK A LANGUAGE
The study of language identiﬁcation described here derives its motiva—
tlon from artificial intelligence. The results and the methods used also

* Present address: Institute for Formal Studies, 1720 Pontius Ave., Los Ange-
193, California 90025. Present sponsor: Air‘Force Ofﬁce of Scientiﬁc Research.
Contract F44620-67~C-0018.

447
Copyright © 1967 by Academic Press Inc.

% ----- new page ---
448 GOLI)

have implications in computational linguistics, in particular the con.
struction of discovery procedures, and in psycholinguistics, in particular
the study of child learning. These implications are discussed in Section 4.

I wish to construct a precise model for the intuitive notion “able to
speak a language” in order to be able to investigate theoretically how it
can be achieved artiﬁcially. Since we cannot explicitly write down the
rules of English which we require one to know before we say he can
“speak English,” an artiﬁcial intelligence which is designed to Speak
English will have to learn its rules from implicit information. That is,
its information will consist of examples of the use of English and/or of
an informant who can state whether a given usage satisﬁes certain rules
of English, but cannot state these rules explicitly.

For the purpose of artiﬁcial intelligence, a model of the rules of usage
of natural languages must be general enough to include the rules which
do occur in existing natural languages. This is a lower bound on the
generality of an acceptable linguistic theory. On the other hand, the con-
siderations of the last paragraph impose an upper bound on generality:
For any language which can be deﬁned within the model there must
be a training program, consisting of implicit information, such that it
it possible to determine which of the deﬁnable languages is being pre-
sented.

Therefore this research program consists of the study of two subjects:
Linguistic structure and the learnability of these structures. This re-
port describes the ﬁrst step of this program. A very naive model of
language is assumed, namely, a language is taken to be a distinguished
set of strings. Such a language is too simple to do anything with (for
instance, to give information or to pose problems), but it has enough
structure to allow its learnability to be investigated as follows: Models
of information presentation are deﬁned, and for each I ask “For which
classes of languages does a learning algorithm exist?”

In the second step of this program (Gold, 1966), which will not be
discussed here, nontrivial models of the usages of language are con-
structed. The next step will be to return to learnability theory and de-
termine whether reasonable training programs exist for linguistic struc-
tures of this type.

2. LANGUAGE IDENTIFICATION MODELS

Appendix II lists intuitive deﬁnitions of some of the terminology 0f
recursive theory used herein. .
Let A be a ﬁnite set (the alphabet of the languages to be considered)

1,
'1‘

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE LIMIT 449
and 23A represent the set of all ﬁnite strings of elements from A. A is
to be considered ﬁxed throughout this paper. The results presented in
the next chapter are independent of the cardinality of A so long as it
is not void. A language L will signify any subset of EA. In an actual
language this may represent, for instance, the set of meaningful strings
of words.

A language learnability model will signify the following triple:

1. A deﬁnition of learnability.

2. A method of information presentation.

3. A naming relation which assigns names (perhaps more than one) to
languages. The “learner” identiﬁes a language by stating one of its
names. The names could be called grammars.

Only one deﬁnition of learnability, which will be called identiﬁability
in the limit, will be considered here. Six alternative methods of informa-
tion presentation and two alternative naming relations will be considered,
making a total of twelve models of language learnability. The deﬁnitions
will now be given, and the results are stated in Section 3. The proofs
are in Appendix I. The basic ideas behind the proofs are described in
Sections 7 and 9. ‘

Time will be taken to be quantized and start at a ﬁnite time:

t=1,2,-~-

At each time t the learner is presented with a unit of information it
concerning the unknown language L. In any language learnability
model, the method of information presentation consists of assigning to
each L a set of allowable training sequences, i1 , i2 , ~ - ~

LEARNABILITY. At each time t the learner is to make a guess 9; of a
name of L based on the information it has received through time t.
Thus the learner is a function G which takes strings of units of informa-
tion into names:

gt=G(i1, "HZ-z)-

L Will be said to be identiﬁed in the limit if, after some ﬁnite time, the
guesses are all the same and are a name of L. A class of languages will
be Called identifiable in the limit with respect to a given language learn-
ability model if there is an effective learner, i.e., an algorithm for making
Ellesses, with the following property: Given any language of the class and
glVen any allowable training sequence for this language, the language will
be identiﬁed in the limit.

FOF each of the 12 models of language learnability the following ques-

% ----- new page ---
450 GOLD

tion has been investigated (the results are in the next Section): Which
classes of languages are identiﬁable in the limit? Note that identiﬁabil-
ity (learnability) is a property of classes of languages, not of individual
languages.

In the case of identiﬁability in the limit the learner does not neces—
sarily know when his guess is correct. He must go on processing informa-
tion forever because there is always the possibility that information
will appear which will force him to change his guess. If the learner were
required to know when his answer is correct (this is equivalent to “ﬁnite
identiﬁability” deﬁned in Section 6), then none of the classes of Ian.
guages investigated in the next chapter would be learnable in any of the
learnability models. My justiﬁcation for studying identiﬁability in the
limit is this: A person does not know when he is speaking a language
correctly; there is always the possibility that he will ﬁnd that his gram.
mar contains an error. But we can guarantee that a child will eventually
learn a natural language, even if it will not know when it is correct.

INFORMATION PRESENTATION. Two basic methods of information
presentation will be considered, “text” and “informant.” Three varia-
tions of each will be deﬁned.

A text for L is a sequence Of strings x1 , x2 , - - - from L such that every
string of L occurs at least once in the text. At time t the learner is
presented x; . Note that for any given language many texts are possible.
The three variations of this method of information presentation to be
considered are Obtained by putting different restrictions on the class of
allowed texts:

1. Arbitrary Text: x. may be any function of t.
‘2. Recursive Text: or. may be any recursive function of t.
3. Primitive Recursive Text: x; may be any primitive recursive function

of t.

An informant for L can tell the learner whether any string is an ele-
ment of L, and does so at each time t for some string y, . Three types 0f
informant will be considered; these differ in how the y; are chosen:
1. Arbitrary Informant: yt may be any function of t so long as every

string of EA occurs at least once.
‘2. M ethodical Informant: An enumeration is assigned a priori to the
strings of EA, and yt is taken to be the tth string of the enumeration-
3. Request Informant: At time t the learner chooses 3/; on the basis 0f
information received so far.
NAMING RELATION. Two naming relations will be considered, “tester"

l

% ----- new page ---
 

 

LANGUAGE IDENTIFICATION IN THE LIMIT 451

and “generator.” In both cases a name of a language, i.c., a grammar,
will be a Turing machine: A tester for L is a Turing machine which is a
decision procedure for L, that is, the Turing machine defines the func-
tion from strings to natural numbers which has the value 1 for strings
in L and O for strings not in L. A generator for L is a Turing machine
which generates L, that is, it deﬁnes a function from positive integers to
strings such that the range of this function is exactly L. A tester exists
iff L is recursive and a generator exists iff L is recursively cnumerable.

Two language learnabz'lity models will be called equivalent if exactly
the same classes of languages are identiﬁable in the limit with respect
to either model. Two naming relations will be called equivalent if, for
every method of information presentation, the two language learnability
models obtained by using these naming relations are equivalent. Simi—
larly, two methods of information presentation will be called equuiatent
if every naming relation yields two equivalent language learnability
models.

Suppose two naming relations are effectively intertranslatablc. That
is, suppose there is an algorithm for each of the naming relations which,
given a name of a language in this naming relation, would yield a name
of the language in the other. Then these are equivalent naming relations.

It is well known that it is possible to effectively translate from testers
t0 generators. Therefore, given any method of information presentation,
any class of languages which is tester-identiﬁable in the limit must also
be generator—identiﬁable in the limit. However, it is not possible to
effectively translate from generators to testers, even if we restrict our-
selves to recursive languages for which both are defined. Therefore,
it is possible for a method of information presentation to exist such that
a class of languages is generator identiﬁable in the limit but not tester
identiﬁable in the limit. An example of this is given in the next Section.
This subject is discussed further in Section 11.

The three variations of information presentation by informant are
equivalent. They are deﬁned separately only in order to make this point.

3. LANGUAGE IDENTIFICATION RESULTS

FOI‘ every pair consisting of one of the 12 learnability models together
With One of the language classes listed in Table I it has been determined
Whether the class of languages is identiﬁable in the limit. The language
Flasses are listed in descending order, i.e., each class is properly contained
111 the class above it. The dividing lines between identiﬁable in the limit

% ----- new page ---
452 GOLD

TABLE I

DIVIDING LINEs BETWEEN LEARNABILITY AND
NONLEARNABILITY 0F LANGUAGES

 

Learnability model Class of languages

Anomalous texta——-————————‘-—>
Recursively enumerable
recursive
Informant/'4
Primitive recursive
Context—sensitive
Context-free
Regular
Superﬁnite

If»

 

Text
Finite cardinality languages

 

“ Anomalous text refers to the use of the generator—naming
relation and information presentation by means of primitive
recursive text.

and nonidentiﬁable in the limit are shown in the table. The classes of
languages below the dividing line shown for a given model of language
learnability are identiﬁable in the limit with respect to this model;
those above the dividing line are not. It is possible to represent the
results by means of dividing lines in this way because of the following
obvious facts: If a class of languages is identiﬁable in the limit with
respect to a given language learnability model, then the same holds
for any subclass; if a class is not identiﬁable in the limit, then the same
holds for any superclass.

In the table, “informan ” refers to any of the three variations of in-
formant together with either the generator— or tester—naming relation.
That is, the same results have been obtained, so far, for each of the six
language learnability models which utilize an informant. Of the six
language learnability models which utilize a text for information presen-
tation, ﬁve of them have given the same results, shown as “text” in the
table. The remaining model, shown as “anomalous text,” is primitive
recursive text with the generator—naming relation.

A super-finite class of languages denotes any class which contains all
languages of ﬁnite cardinality and at least one of inﬁnite cardinality.

The anomalous model using a text is of no practical interest, but
three noteworthy conclusions can be drawn from it: (1) It shows that

x

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE LIMIT 453
restrictions on the order of presentation of elements of the text can
greatly increase the learnability power of this method of information
presentation. (2) Note that the difference between a text and an in-
formant is that a text only presents the learner with positive instances,
namely, elements of the language, whereas an informant presents both
positive and negative instances. Therefore, one would expect the in—
formant to be more powerful. However, “anomalous text” is more
powerful than any of the “informant” models, which shows that one
must carefully consider the details of the learnability model. (3) “Anom-
alous text” shows that the choice of naming relation can make a difv
ference since, in this case, the generator—naming relation is far more
powerful than tester.

4. IMPLICATIONS OF LANGUAGE LEARNABILITY RESULTS

To THE STUDY OF CHILD LEARNING OF LANGUAGE. Recently, psycho-
linguists have begun to study the acquisition of grammar by children
(e.g., McNeill, 1966). Those working in the ﬁeld generally agree that
most children are rarely informed when they make grammatical errors,
and those that are informed take little heed. In other words, it is be-
lieved that it is possible to learn the syntax of a natural language solely
from positive instances, i.e., a “text.” However, the results presented
in the last Section show that only the most trivial class of languages
considered is learnable (in the sense of identiﬁcation in the limit) from
text, neglecting “anomalous text.” If one accepts identiﬁcation in the
limit as a model of learnability, then this conﬂict must lead to at least
one of the following conclusions:

1. The class of possible natural languages is much smaller than one
would expect from our present models of syntax. That is, even if Eng—
lish is context-sensitive, it is not true that any context-sensitive lan—
guage can occur naturally. Equivalently, we may say that the child
starts out with more information than that the language it will be pre-
sented is context-sensitive. In particular, the results on learnability
from text imply the following: The class of possible natural languages,
if it contains languages of inﬁnite cardinality, cannot contain all lan-
guages of ﬁnite cardinality.

2. The child receives negative instances by being corrected in a way
We do not recognize. If we can assume that the child receives both posi-
tive and negative instances, then it is being presented information by an
“informant.” The class of primitive recursive languages, which includes

% ----- new page ---
454 GOLD

the class of context—sensitive languages, is identifiable in the limit from
an informant. The child may receive the equivalent of negative i11-
stances for the purpose of grammar acquisition when it does not get
the desired response to an utterance. It is difﬁcult to interpret the actual
training program of a child in terms of the naive model of a language
assumed here.

3. There is an a priori restriction on the class of texts which can occur,
such as a restriction on the order of text presentation. The child may
learn that a certain string is not acceptable by the fact that it neVer
occurs in a certain context. This would constitute a negative instance,

To ARTIFICIAL INTELLIGENCE. The training program of an artiﬁcial
intelligence can certainly include an informant, whether or not children
receive negative instances. Therefore, the results of Table I show that a
learning algorithm can be constructed for the identiﬁcation of primitive
recursive predicates on strings, which probably include all the predi—
cates children learn. However, for the purpose of efﬁciency it is still of
significance to determine what additional information may be available
to children, either in the form of an a priori restriction on the class of
predicates which can occur in natural languages, or in the form of in-
formation which can be obtained from the order of presentation of
naturally occurring texts.

To THE CONSTRUCTION ORDISCOVERY PROCEDURES. Attempts have
been made to construct an algorithm for automatically generating a
phrase structure grammar for a language solely by analyzing a text of
the language. One approach (Lamb, 1961) uses the “distributional
analysis” of Harris (1951, 1964) and Hockett (1958). Namely, one asso-
ciates phrases which are found to occur in the same context, thereby
defining phrase categories and simultaneously enlarging the set of con-
texts which can be considered equivalent; then one records how phrase
categories are constructed by concatenation of phrase categories.
Another approach which has been proposed (Solomonoff, 1964) uses
“identiﬁcation by enumeration,” which is defined in Section 7.

These attempts suggest the question, “Is there enough information in
a text, even one of unlimited length, to allow the identification of a con-
text—free language?” The results presented in Section 3 ShOVV that it is
impossible to construct a learning algorithm for the entire class 0f
context—free languages if the only information is an arbitrary text. If
one wishes to assume restrictions on the order of presentation of the
text, then a successful learning algorithm must be sensitive to the Ol‘der

1

% ----- new page ---
LANGUAGE“IDENTIFICATION IN THE LIMIT 4.3.")

of the text. Thus, statistical approaches such as distributional analysis
are not suitable for this purpose. However, it would be useful to deter-
mine if there are interesting subclasses of the class of context—free lan—
guages which can be identiﬁed in the limit by either of these approaches.

5. IDENTIFICATION OF FUNCTIONS AND BLACK BOXES

This, Section is a summary of the results of a previous paper (Gold,
1965) which is devoted to the learnability of two types of objects other
than languages:

TIME FUNCTION. At each time t, a time function produces an output, a
positive integer, which depends only on t. Formally, a time function is a
function of one variable which takes positive integers (time) into posi-
tive integers (outputs).

BLACK BOX. A black box has provision for an input at each time, as
well as an output. Each output is determined by the inputs that have
previously been applied to the black box. More precisely, let an alphabet
here signify either a ﬁnite set with at least two elements, or else the set
of positive integers. Then a black box consists of the following triple:
An input alphabet I; an output alphabet 0; a black box function I)
which takes input strings into the output alphabet, thereby determin-
ing the output at time t: 0, = b(i1 , - - - , it).

Thus, a time function is a special case of a black box. In the case of a
time function, 0; depends only on t and not on a previous input string.
A time function can be described as a black box with a degenerate input
alphabet consisting of one element.

Throughout the study of black box learnability, I and 0 are to be
considered as ﬁxed alphabets, i.e., I and 0 are chosen a priori, and all
black boxes are to use these two alphabets.

III the case of time function learnability the following situation is
studied. The learner observes the successive outputs of a time function
and is to guess what function it is observing; that is, the learner consists
Of an identity guessing algorithm G which yields a guess gt at each time
tas to the identity of the time function, gt being determined by the out«
puts which the time function has produced so far: gt = G( 01 , - - - , 0;).

III the case of black box identiﬁcation, the learner consists of an ex-
perimenting algorithm E as well as an identity guessing algorithm 0.
E determines the input which the learner will apply to the unknown
black box at any time as a function of the previous outputs of the black
bOX: 2') = E( 01, , OH). The identity guessing algorithm makes a

% ----- new page ---
456 GOLD

TABLE II
DIVIDING LINEs BETWEEN LEARNABILITY AND
NONLEARNABILITY FOR TIME FUNCTIONS AND
BLACK BOXES

 

Type of object Class of objects

 

Recursive
Time functions————————-‘>
Primitive recursive
Black boxes——————————————>
Finite automata

 

guess, at each time t, as to the identity of the black box: 9, =
G(01, ,0;).

It is too much to require the learner to identify a black box in the
sense of ﬁnding its identity at the beginning of the experiment, t = 1.
This is because, for instance, the black box may be such that the ﬁrst
input which the learner applies to it may trap the black box in a subset
of its possible states, so that the learner will never be able to determine
what the behavior of the black box would have been if its ﬁrst input had
been different. Therefore, only weak learnability will be considered;
namely, the learner will be asked to predict, at each time, the future
behavior of the black box. That is, the learner is to guess the present
black box function, rather than that at t = 1.

Only one model of time function learnability and one of black box
learnability will be considered. The method of information presentation
for each model was described above. As in the models of language learn-
ability, in both of these models “learnability” will signify “identiﬁca-
tion in the limit.” The naming relation will be the following: The names
of a time function, or of a black box (actually, its black box function),
will be taken to be those Turing machines which compute it.

Three classes each of time functions and of black boxes have been
considered. Table II shows which of these are identiﬁable in the limit.
As in Table I, the classes are listed in descending order in Table II.
Finite automata time functions denote ultimately periodic functions.

6. ABSTRACT MODEL OF IDENTIFICATION

An identiﬁcation situation consists of the following three items:

1. A class Q of objects. One of the objects will be chosen, the learner
will be presented information about it, and the learner is to ﬁgure 01113
which one it is.

M!“

% ----- new page ---
 

LANGUAGE IDENTIFICATION IN THE LIMIT 457

2. A method of information presentation. At each time t the learner
receives a unit of information it which is chosen from a set I . The method
of information presentation consists of specifying, for each a) E (2, which
sequences of units of information, i1 , i2 , - - - , are allowable. Let the set
of allowable sequences be designated I 0°(co).

3, A naming relation. The learner is to identify the unknown object
by ﬁnding one of its names. A naming relation consists of a set N of
names and a function f which assigns an object to each name, f: N~i> $2.

The identiﬁcation problem is to determine whether there is a rule the
learner can use to accomplish the following: For any object at E (2
and for any information sequence from I °°( w), on the basis of that in-
formation sequence the rule will yield a name n of a), that is, f(n) = to.
Three variations of the identiﬁcation problem are the following, of
which only the ﬁrst is considered in this paper.

Identiﬁcation in the limit has made some appearances previously in
the pattern recognition literature (e.g., Aizerman et al., 1964). In this
case the learner is to guess a name of the unknown object at each time.
It is required that there be a ﬁnite time after which the guesses are all
the same and are correct. ,

Finite identiﬁcation is the type of identiﬁcation problem usually
considered. It is best known in automata theory (e.g., Gill, 1961). In
ﬁnite identiﬁcation, the learner is to stop the presentation of information
at some ﬁnite time when it thinks it has received enough, and state the
identity of the unknown object. This is not possible unless there is some
ﬁnite time at which the information distinguishes the unknown object.
That is, no other object satisﬁes the information.

Fixed-time identiﬁcation. In this case the information sequence stops
after some ﬁnite time which is speciﬁed a priori and which is independ—
ent of the object being described. The learner is to then state the identity
of the unknown object.

Saying that a class of objects is identiﬁable in the limit implies not
only that a suitable guessing function G exists, but that it is effective;
that is, there exists an algorithm which computes it. The class of objects
Will be called ineﬁectively identiﬁable in the limit if a suitable G exists,
regardless of whether it is effective. Note that whether a class of objects
‘5 ineffectively identiﬁable in the limit does not depend on the naming
relation so long as every object has at least one name. This is because any
tW0 naming relations are intertranslatable if we do not require translation
to be effective.

A11 identiﬁcation situation will be said to satisfy the distinguishability

% ----- new page ---
458 GOLD

condition if the I 0c(w) are disjoint; that is, if there is no informat'mn
sequence which describes two different objects.

An identiﬁcation situation will be said to satisfy the collapsing un-
certainty condition if the following holds: For any information string
i1 , - ~ - , it , let 9; denote the set of those objects which agree with the
information received so far, i.e., those as such that I 0°(ca) contains an
information sequence which begins i1, , it. For any informat'mn
sequence, the (2; will be a descending sequence. The collapsing uncer-
tainty condition requires that, for any object to and any information
sequence of I cc’(w), the limit set of the 9; contains only to. That is, for
any to, different from to there is a time after which the information will
eliminate w], namely to, 6 Q, .

7. METHODS OF IDENTIFICATION IN THE LIMIT

Identification by enumeration refers to the following guessing rule;
Enumerate the class of objects in any way, perhaps with repetitions.
That is, choose a function from the positive integers to the class of ob-
jects such that the range of the function is the entire class. At timet
guess the unknown object to be the ﬁrst object of the enumeration which
agrees with the information received so far, i.e., which is in Qt. This
guessing rule will be effective if the following two conditions hold: (1)
Given any information string i1, , i; and any positive integer ii,
there is an effective method for determining whether the nth object of
the enumeration is in KL . (2) There is an effective method for ﬁnding a
name of the nth object of the enumeration.

To be precise, “identification by enumeration” refers to a class of
guessing rules, since there are many possible enumerations.

If we assume that I is countable, then any class of objects which is
ineffectively identiﬁable in the limit must be countable. This is because
the domain of the guessing function G, namely, ﬁnite strings of elements
of I, is countable.

Henceforth, it will be assumed that I and Q are countable, and that
every object has at least one name.

THEOREM 7.1. For ineﬁectioe identiﬁability in the limit, the distinguish-
ability condition is necessary and the collapsing uncertainty condition is
su icient. Indeed, the collapsing uncertainty condition implies that
identification by enumeration gioes ineﬁective identiﬁcation in the liml
for any enumeration. I f I 0"(m is countable for every 0.), then the distinguisl“
ability condition is suﬁicient for ineffective identiﬁability in the limit-

PROOF. Ineffective identiﬁability in the limit => distinguishabilit"

1—.

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE» LIMIT 459
If the distinguishability condition does not hold, then there is an allow-
able information sequence which describes two different objects, so that
it is impossible to know which is the unknown object.

Collapsing uncertainty => identification by enumeration gives ineffec-
tive identiﬁcation in the limit for any enumeration: The object to be
identiﬁed must occur somewhere in the enumeration. Let its ﬁrst occur-
rence be at position n, There are at most n — 1 different objects before
this position in the enumeration. The collapsing uncertainty condition
implies that there is some ﬁnite time after which none of these prior
objects will agree with the information presented to the learner. After
that time the unknown object will be the ﬁrst object of the enumeration
which satisﬁes the information received, and will therefore be correctly
guessed by the learner.

I°°(w) is countable for every (0, together with distinguishability 2? in-
effective identiﬁability in the limit. If we wish to identify the information
sequence, then the collapsing uncertainty condition always holds. Say-
ing that I ”(w) is countable for every 0) is equivalent to saying that the
set of allowable information sequences is countable. In this case, iden-
tiﬁcation by enumeration may be used to‘identify in the limit the in-
formation sequence being presented to the learner. The distinguishability
condition implies that one can translate (not necessarily effectively)
from information sequences to objects, and therefore to names of ob-
jects. QED.

Returning to the speciﬁc case of language identiﬁcation, note that in-
formation presentation by informant satisﬁes the collapsing uncertainty
condition no matter what class of languages is considered. That is why
the class of primitive recursive languages is identiﬁable in the limit from
an informant; namely, an effective enumeration of the characteristic
functions of this class of languages exists thereby giving an effective
identiﬁcation-by—enumeration guessing rule (see Theorem 1.4, Ap-
pendix 1).

Information presentation by text satisfies the distinguishability con—
dition for any class of languages, but it does not satisfy collapsing un-
Certainty for any class of languages which contains two languages such
that one is a subset of the other.

The following guessing algorithm shows that the class of languages of
ﬁnite cardinality is identiﬁable in the limit from an arbitrary text:
Gruess the unknown language to consist solely of the strings generated so
far by the text (see Theorem 1.6).

To see that the entire class of recursively cnumerable languages is

% ----- new page ---
460 GOLD

identiﬁable in the limit from primitive recursive text using the generatm
naming relation (see Theorem 1.7), note that the class of primitiVe re.
cursive texts is effectively enumerable. Therefore, the text can be effec_
tively identiﬁed in the limit using identiﬁcation by enumeration. SinCe
the text is a generator for the language, this is all that is needed. This is
an example of the method of identiﬁcation described at the end of the
proof of Theorem 7.1.

8. INEFFECTIVE IDENTIFIABILITY IN THE LIMIT RESULTS

LANGUAGE IDENTIFIABILITY. If information presentation is by inform.
ant, then the collapsing uncertainty condition is satisﬁed, so that any
countable class of languages is ineffectively identiﬁable in the limit using
identiﬁcation by enumeration. Of course, all the languages must haVe
names.

If information presentation is by recursive or primitive recursive text,
then, again, any countable class of languages is ineffectively identifiable
in the limit. This is because there are only a countable number of pos-
sible texts, so that the text can be identiﬁed in the limit by means of
identiﬁcation by enumeration.

If information presentation is by arbitrary text, then the results for
ineffective identiﬁability in the limit are the same as for effective identi-
ﬁability in the limit; namely, the class of languages of ﬁnite cardinality
is ineffectively identiﬁable in the limit, but every proper superclass is
not. This can be proved by the same methods used to prove Theorems
1.6 and 1.8.

TIME FUNCTION IDENTIFIABILITY. The method of information presen-
tation in the model of time function learnability satisﬁes the collapsing
uncertainty condition. Therefore, any countable class of time functions
is ineffectively identiﬁable in the limit.

BLACK Box IDENTIFIABILITY. Any countable class of black boxes is
ineffectively (weak) identiﬁable in the limit. This can be proved by the
same method used to prove Theorems 9 and 10 in Gold (1965).

9. THE WEAKNESS OF TEXT

It is of great interest to ﬁnd why information presentation by text is
so weak and under what circumstances it becomes stronger. Therefore,
it is worthwhile to understand the method used in Theorems 1.8 and
1.9 to prove that any class of languages containing all ﬁnite languaz‘ges
and at least one inﬁnite language is not identiﬁable in the limit from 9'
text in ﬁve out of six of the models using text.

l,"

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE LIMIT 461

The basic idea is proof by contradiction. Consider any proposed guess-
ing algorithm. It must identify any ﬁnite language correctly after a
ﬁnite amount of text. This makes it possible to construct a text for the
inﬁnite language which will fool the learner into making a wrong guess
an inﬁnite number of times as follows. The text ranges over successively
larger, ﬁnite subsets of the inﬁnite language. At each stage it repeats
the elements of the current subset long enough to fool the learner.

Thus, the method of proof of the negative results concerning text
depends on the possibility of there being a huge amount of repetition
in the text. Perhaps this can be prevented by some reasonable probabil-
istic assumption concerning the generation of the text. In this case one
would only require identiﬁcation in the limit with probability one,
rather than for every allowed text.

I have been asked, “If information presentation is by means of text,
why not guess the unknown language to be the simplest one which ac—
cepts the text available?” This is identiﬁcation by enumeration. It is
instructive to see why it will not work for most interesting classes of
languages: The universal language (if it is in the class) will have some
ﬁnite complexity. If the unknown language is more complex, then the
guessing procedure being considered will always guess wrong, since the
universal language is consistent with any ﬁnite text. This follows from
the fact that, if L is the unknown language and if L, I) L, then L, is con-
sistent with any ﬁnite segment of any text for L. The problem with text
is that, if you guess too large a language, the text will never tell you that
you are wrong.

10. LEARNING TIME

Consider an identiﬁcation situation which satisﬁes the collapsing un-
certainty condition. Choose an enumeration of the class of objects and
let Go be the identiﬁcation—by-enumeration guessing rule which uses this
enumeration. At ﬁrst sight, identiﬁcation by enumeration appears to be
a naive approach to learning. However, it will be shown that Go is the
most efﬁcient possible guessing rule with respect to learning time. This
hOIds even if ineffective guessing rules are allowed and if the enumeration
has duplications. This result is somewhat surprising in View of the fact
that there are many different identiﬁcation-by-enumeration guessing
rules, obtained by using different enumerations. This means that none of
them is uniformly better than any other, in the sense deﬁned below, for
the purpose of minimizing learning time.

% ----- new page ---
462 GOLD

Let G be any guessing rule, to be any element of the class 52 of Objects
and i any information sequence allowed for w. Deﬁne the learning timé
~r( G, co, 7“,) to be the ﬁrst time such that at that time and all following times
all the guesses of G as to the identity of (0 will be the same and correct.
Define the learning time to be on if no such time exists.

Let G and G’ be any two guessing rules. G will be said to be uniformly
faster than G, if the following two conditions hold: ( 1) Given any w and
any allowable i for w, then G will identify 0) at least as soon as G' will
identify 0), that is,

7(G, w, i) g 7(0’, (.0, o.

(2) There is some we and an allowable to for 030 such that G will identify
coo sooner that G]:

7(G, mg, a) < 7(0’, we, in)

THEOREM 10.1. If Go is an identiﬁcation-by-enumeralion guessing rule,
then there is no guessing rule uniformly faster than G0 .

PROOF. This is what has to be proved: Let G be any guessing rule. If
there is an a) and an allowable i for w such that G is faster than G0 , i.e.,
T(G, w, T) < 7(G0, w, i), then there is an m, and an allowable ii, for a),
such that Go is faster than G, i.e., 7(Go , w’, i') < r( G, 0.)], i’).

G0 is constructed in such a way that, once it guesses correctly, its
guesses never change. Therefore, if G, is presented with the object on to
identify, by being given information sequence i, then 7-(Go , w, i) is the ﬁrst
time that Go guesses the identity of the unknown object to be a). At the
earlier time, 1(G, w, 1), G0 must guess the name of some other object, say
0/. At any time that Go guesses the name of an object, that object must
agree with the information received so far. That is, at the time that Go
guesses w, there must be an allowable i’ for a), such that i’ is the same as
1 up to this time. Thus, if w, were the unknown object and i' the informa-
tion sequence, then at that time, namely ’7'( G, on, i), G and G0 would make
the same guesses as they would if presented a) and 7: G0 would guess u
and G would guess 0.). That is, if presented with w, and i', G0 would be
correct before G. Q.E.D.

Note that the proof of Theorem 9.1 remains valid even if G0 does not
identify every object of the class in the limit and G does. It is only neces-
sary that, for every finite initial subsequence of every allowable informa‘
tion sequence, there exist an object in the enumeration which is consistent
with it.

% ----- new page ---
LANGUAGE gDENTIFICATION IN THE LIMIT 463

11. TRANSLATION FROM GENERATORS T0 TESTERS

The purpose of this Section is to use the results on language identiﬁca—
tion in the limit presented in Section 3 to solve a problem in recursive
theory. In addition to the generator- and tester-naming relations, a third
method of assigning names to recursive sets, called domain generators.
is deﬁned below. Suzuki (1959) has shown that there is no effective
method for going from recursive sets, described by domain generators,
to their complements, described in the same way. This result will here be
strengthened in two ways: It will be shown that there is no 2-recursive
(deﬁned below) translation of this type, and that, rather than the entire
class of recursive sets, one can restrict one’s consideration to any class of
sets which contains all ﬁnite sets and at least one inﬁnite set without
changing this result. It has been pointed out to me by Norman Shapiro
that one can easily construct a 3-recursive translation from recursive
sets to their complements, using the domain generator—naming relation,
thus completely establishing the difﬁculty, in the Kleene hierarchy, of
this type of translation.

For the purpose of this Section it is desirable to think of languages as
sets of positive integers, rather than sets of strings. This may be accom-
plished by means of any recursive one-to—one correspondence between
the strings of EA and the positive integers.

Let Zn(x) be the number-theoretic function of one variable deﬁned
by the Turing machine whose Godel number is n. The two naming rela-
tions for languages are deﬁned formally as follows.

Generator. A generator for L is a positive integer n such that L is the
range of Zn(.r).

Tester. A tester for L is a positive integer n such that Zn(x) = X L(:c),
where XL is the characteristic function of L.

It will be assumed in this Section that in all naming relations the
names are numbers.

Translation. Given two naming relations, N1 and Na , a translation from
N1 to N 2 is a partial, number-theoretic function f( n) such that, if n is a
name of an object in N1 , then f (n) is deﬁned and is a name of that object
in N2 .

Limiting recursive function. A partial, number-theoretic function f( n)
will be called limiting recursive if there is a total recursive “guessing
function” g(n, t) such that

f(n) = limtg(n, t), (10.1)

% ----- new page ---
464 GOLD

where the limit of a sequence of positive integers is taken to be undeﬁned
if the sequence is not constant after some ﬁnite point; otherwise the
limit is defined to be the value at which the sequence ultimately becomes
constant.

THEOREM 10.1. If a class of objects is identiﬁable in limit using some
method of information presentation and using naming relation N1 , and if
there is a limiting recursive translation from N1 to naming relation N2,
then the class of objects is identiﬁable in the limit using the same method of
information presentation and N 2 .

PROOF. Let f(n) be a limiting recursive translation from N1 to N2,
and g(n, t) be a total recursive function such that Eq. (10.1) holds, and
let G1 be a suitable guessing rule using N1 . Then a suitable guessing rule
using N2 is the following:

For a given information sequence, suppose that at time t the guess made
by G1 is g; . Then, when using N2 , let the guess he g(gt , t). Call this
guessing rule G2 .

To see that G2 is suitable note that, using N1 , there is a time t1 after
which all the g; will equal a ﬁxed value go , which is correct in N1 .By
Eq. (10.1), there is a t2 such that, for all t 2 t2 ,

Mo) = g(go , t). (10.2)

Therefore, for all times greater than t1 and t2 , the guess of G2 will be
f(g0), which is correct in N2 . Q.E.D.

Consider language learnability with information presentation by
means of primitive recursive text. The results shown in Table I differ for
the two naming relations, generator and tester. This leads to the follow-
ing conclusion:

COROLLARY 10.1. If C is a class of languages which contains all ﬁnite
languages and at least one inﬁnite recursive language, then there is no limit-
ing recursive translation from testers for C to generators.

In order to compare this result with that of Suzuki, it is necessary t0
deﬁne two more naming relations for recursive languages:

Domain generator. A domain generator for L is a positive integer n such
that L is the domain of Zn(x).

Anti-domain generator. n is an anti-domain generator for L if it is a
domain generator for the complement of L.

Representing predicate. For any partial number-theoretic function
f(n), its representing predicate P (n, m) will be deﬁned to be true for jUSt
those pairs (n, m) such that ﬁn) is deﬁned and f(n) = m.

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE LIMIT 465
4“)

lc-Recursive function. A partial, ndmber~theoretic function will be called
A'-recursive if its representing predicate is k—r.e. (recursively enumerable)
in the Kleene hierarchy.

Note that the l-recursive functions are just the partial recursive
functions.

It is shown elsewhere (Gold, 1965) that the limiting recursive func-
tions are the same as the 2—recursive functions.

The strengthening of Suzuki’s result described at the beginning of this
chapter can now be stated formally:

THEOREM 10.2. If C is a class of languages which contains all ﬁnite
languages and at least one infinite recursive language, then there is no 2—re-
curs/ice translation from domain generators for C to anti-domain generators.

PROOF. Theorem 10.2 follows from Corollary 10.1 together with the
following facts which can be proved by standard methods:

There is a partial recursive translation from testers to domain gener—
ators.

Given both a domain generator and an anti-domain generator for a
recursive set, there is an effective procedure for ﬁnding a generator for it.

Composition of 2-recursive and recursive functions yields 2-recursive
functions. QWED

12. INDUCTIVE INFERENCE

Concerning inductive inference, philosophers often occupy themselves
with the following type of question: Suppose we are given a body of
information and a set of possible conclusions, from which we are to
choose one. Some of the conclusions are eliminated by the information.
The question is, of the conclusions which are consistent with the in-
formation, which is “correct”?

If some sort of probability distribution is imposed on the set of con-
clusions, then the problem is meaningful. But if no basis for choosing
between the consistent conclusions is postulated a priori, then inductive
inference can do no more than state the set of consistent conclusions.

The difﬁculty with the inductive inference problem, when it is stated
this way, is that it asks, "What is the correct guess at a speciﬁc time
With a ﬁxed amount of information?” There is no basis for choosing
betWeen possible guesses at a speciﬁc time. However, it is interesting
to study a guessing strategy. NOW one can investigate the limiting be-
hELVior of the guesses as successively larger bodies of information are
Considered. This report is an example of such a study. Namely, in in-

% ----- new page ---
466 GOLD

teresting identiﬁcation problems, a learner cannot help but make errors
due to incomplete knowledge. But, using an “identiﬁcation in the limit”
guessing rule, a learner can guarantee that he will be wrong only a
ﬁnite number of times.

RECEIVED: February ‘20, 1967

REFERENCES

AIZERMAN, M. A,, BRAVERMAN, E. M., AND ROZONOER, L. I. (1964). Theoretical
foundations of the potential function method in pattern recognition. Antonia-
tion and Remote Control 25, 821—837 and 1175-1190.

GILL, A. (1961). State-identiﬁcation experiments in ﬁnite automata. Information
and Control 4, 132-154.

GOLD, E MARK (1965). Limiting recursion. J. Symb. Logic 30, 28—48.

GOLD, E MARK (1966). “Usages of Natural Language.” Informal report available
from the author at Institute for Formal Studies, 1720 Pontius Ave, Los
Angeles, California 90025.

HARRIS, ZELLIG (1951). “Methods in Structural Linguistics.” Univ. of Chicago
Press.

HARRIS, ZELLIG (196-1). Distributional structure. In “The Structure of Language”
(J. A. Fodor and J. J. Katz, eds.). Prentice Hall, New York.

HOCKETT, C. F. (1958). “A Course in Modern Linguistics.” Macmillan, New York.

LAMB, SYDNEY, M. (1961). On the mechanization of syntactic analysis. In “1961
Conference on Machine Translation of Languages and Applied Language
Analysis” (National PhysicalLaboratory Symposium No. 13), Vol. II, pp.
674—685. Her Majesty’s Stationery Ofﬁce, London.

MCNEILL, DAVID (1966). Developmental psycholinguistics. Part of the chapter
“Psycholinguistics” by George Miller and David McNeill to appear in the
“Handbook of Social Psychology.”

SOLOMONOFF (1964). A formal theory of inductive inference. Information and
Control 7, 1-22 and 224-254.

SUZUKI, Y. (1959). Enumeration of recursive sets. J. Symb. Logic 24, 311.

APPENDIX I
PROOFs 0F LANGUAGE IDENTIFICATION RESULTS

It can be shown by standard methods that there is a recursive transla-
tion from testers to generators. Thus, Theorem 10.1 gives

THEOREM 1.1. Given any method of information presentation, if a class
of languages is identiﬁable in the limit using the tester-naming relation,
then it is identiﬁable in the limit using the generator-naming relation.

COROLLARY 1.2. Given any method of information presentation, if a

class of languages is not identiﬁable in the limit uszng the generator—naming

% ----- new page ---
LANGUAGE "IDENTIFICATION IN THE LIMIT 467
relation, then it is not identifiable in the limit using the tester-naming rela—
tion.

THEOREM 1.3. Arbitrary informant, methodical informant, and request
informant are equivalent methods of information presentation.

PROOF. Identiﬁability from arbitrary informant => identiﬁability from
methodical informant => identiﬁability from request informant: The ﬁrst
implication follows from the fact that an identity guessing algorithm
which will work for any informant will obviously work for the special
case of a methodical informant. The second follows from the fact that the
learner can ask a request informant for methodical information.

Identiﬁability from request informant => identiﬁability from arbitrary
informant: Suppose we have an identity guessing algorithm suitable for a
request informant and we are faced with an arbitrary informant. What-
ever information our learner wishes to request at some time, an arbitrary
informant is required to provide it eventually. We can modify our learner
so that it will wait until it receives the information it currently desires be-
fore it makes its next guess. Q.E.D.

The previous ﬁve theorems and corollaries compare the methods of
information presentation and the naming relations for language identiﬁca-
tion. These results, together with the following six theorems, yield the
language learnability results presented in Table I.

As in Section 10, it will be desirable to think of languages as sets of
positive integers, rather than of strings. However, here it will be neces-
sary to achieve this by means of a primitive recursive one—to-one cor-
respondence, so that primitive recursive sets of strings will be taken into
primitive recursive sets of positive integers and vice—versa.

THEOREM 1.4. Using information presentation by methodical informant
and the tester-naming relation, the class of primitive recursive languages IS
identiﬁable in the limit.

PROOF. There is an effective enumeration of the primitive recursive
functions of one variable, that is, a total recursive function pn(x) of two
Variables such that the class of p" is the class of primitive recursive func-
tions. Deﬁne w(.r) to be the function which takes 1 into 1 and all other
Values of a: into 0. Then 7.01),,(1‘) is an effective enumeration of the char—
acteristic functions of the primitive recursive languages. Let L" be the
1anguage whose characteristic functionis ivpn . It willnow be shown that
identiﬁcation by enumeration using this enumeration of the primitive
I‘QCUrsive languages is effective. First it must be shown that, given any

% ----- new page ---
468 GOLD

information sequence up to time t and any n, it can be effectively deter-
mined whether Ln satisﬁes this information sequence. The informatim1
sequence will tell us, for each a; from 1 through t, whether at is an Element
of the unknown language L. The fact that apnea) is a recursive 2—plage
function implies that we can effectively determine the desired informa-
tion, namely, whether or not each x from 1 through t is an element of Ln .
Now it only remains to show that a tester can effectively be found for
L. . This follows from the well known result of recursive theory that, for
any recursive 2—place function 101M707 there is a total recursive function
-¢(n) such that

Z¢(n)(x) = wpn(x); (1.1)

that is, ¢(n) is a tester for Lu .

THEOREM 1.5. Using information presentation by methodical informant
and the generator-naming relation, the class of recursive languages IS NOT
identiﬁable in the limit.

PROOF. Let G be an effective identity guessing rule for methodical
informant which correctly identiﬁes in the limit every ﬁnite language and
the complement of every ﬁnite language. A recursive language L will be
constructed for which the guesses of G will change an inﬁnite number of
times.

The information sequence for L will be a semi-inﬁnite sequence of 0’s
andl’s:i1,i2, ,whereit = liftE L,i, = 0ift$ L.Aneffective
rule will be given for constructing this sequence. The construction will
proceed in steps. If at the beginning of a step of the construction the
construction has so far produced i1 , - - - , in , then at the end of the step
the information sequence will have been extended to be of the form

i1, ”1,0”, 1”, (1.2)

where ab denotes a b-long string of a’s. An effective procedure will be
given for choosing x and g which will guarantee that the guess made by
G at the end of string 1.2 will be different from the guess made earlier, at
the end of the information string

i17"‘,7:n,01. (1.3)

It is only necessary to show that a pair (at, y) with this property exists;
because then such a pair can be effectively found as follows: Meth'

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE‘LIMIT 469

‘I

Odieally search all pairs of positive integers until such a pair is found.
That one can effectively determine, for any pair, whether it has the de—
sired property follows from the fact that G is effective.

Let L1 be the language whose information sequence is

i17"‘77:n70w7 (14)

where a°o denotes the semi—inﬁnite string a, a, - - - . Since L1 is a ﬁnite
language, if G is presented with this information sequence it must, after
some ﬁnite time, continually guess a generator g1 for L1 . Let n + x be a
time at which G guesses g1 .

Let L2 be the language whose information sequence is

2'1, Mt,0”,1°°. (1.5)

Since L2 is the complement of a ﬁnite language, if G is presented with
this information sequence, there must be a time n + x + y at which 6’
guesses a generator g2 for L2 . Since g1 and g2 must differ, this shows the
existence of a pair (at, y) with the desired property. Q.E.D.

THEOREM 1.6. Using information presentation by arbitrary text and the
tester-naming relation, the class of languages ‘ofﬁnite cardinality IS identi-
ﬁable in the limit.

PROOF. The information sequence i1 , i2 , - - - will be a sequence of posi—
tive integers, the range of which is the unknown language L. A suitable
identity guessing algorithm is the following: At time t, guess L to consist
solely of the numbers which have occurred so far in the information
sequence. Since L is ﬁnite, there will be a ﬁnite time after which all ele—
ments of L will have occurred in the information sequence, so that the
guesses will be correct. It is a straightforward but tedious exercise to
show that there is an effective method for ﬁnding a tester for the language
which consists of i1 , - - - , it . Q.E.D.

THEOREM 1.7. Using information presentation by primitive recursive
text and the generator—naming relation, the entire class of re. languages IS
identiﬁable in the limit.

PROOF. As in Theorem 1.4, let pn(x) be an effective enumeration of the
primitive recursive functions. The information sequence i1 , i2 , - - - will
be the same as the sequence pn(1), pn(2), - - - for some n. Such an n can
be effectively identiﬁed in the limit by using identiﬁcation by enumer—
ation. That is, the text describing the unknown language L can be identi—
ﬁEd in the limit. Since pn(x) is a recursive function of two variables,

% ----- new page ---
470 GOLD

there is a total recursive function d>(n) such that
Z¢(n)(90) = 13433); (1.7)

that is, ¢(n) is a generator for L. QED.

THEOREM 1.8. Using information presentation by recursive text and the
generator-naming relation, any class of languages which contains all ﬁnite
languages and at lease one inﬁnite language L IS NOT identiﬁable in the
limit.

PROOF. We may assume that L is r.e. since, otherwise, it would not
have a generator and the theorem would follow immediately. It can be
shown by straightforward methods that there is a recursive sequence of
positive integers a1 , a2 , ~ -- which ranges over L without repetitions.
Suppose G is an effective identity guessing rule which identiﬁes generators
for all ﬁnite languages in the limit from recursive text. A recursive text
for L will now be constructed which will cause G to change its guess an
inﬁnite number of times. This text will be of the form

”£1,715, = afﬁagﬂ . (1.8)
As in the proof of Theorem 1.5, this text will be constructed in steps. Let

At the beginning of the nth step, the desired information sequence will
have been constructed through time t2”-2. During the nth step, 3:2,.-1
and 902,, will be effectively chosen in such a manner that the guess made
by G at time 1527.4 will differ from that at time t2” . As in the proof of
Theorem 1.5, it is sufﬁcient to show that such a pair (x2n_1 , x2") exists.
' Let in signify the desired information sequence through time t,, . The
information sequence

1'1, i2 , --- = 12.1-2 , (132-1 (1.10)
is a recursive text for the ﬁnite language
L1 = {(11, ,azn-1}. (1.11)

Therefore, there is an x2n_1 such that at time t2n_1 the guess made by 0
Will be a generator for L1 . Similarly, the information sequence

7:1 ) i2 5 ' ' ' = llZn—l 7 a?" (1'12)
is a recursive text for the ﬁnite language
L2 = {(11, ,aan}, (1-13l

% ----- new page ---
LANGUAGE IDENTIFICATION 1N THE LIMIT 471
‘7

which is different from L1 . For a large enough $2,. the guess made by G
at time t2” will be a generator for L2 , which cannot be the same as a
generator for L1 . QMED

THEOREM 1.9. Using information presentation by primitive recursive
text and the tester-naming relation, any class of languages which contains
all ﬁnite languages and at least one inﬁnite language L IS NOT identifiable
in the limit.

PROOF BY CONTRADICTION. An information sequence i1 , i2 , - - - is here
a sequence of positive integers. A guessing rule consists of a computable
function G which determines the guess g; at time t as a function of the
information received by the learner through t:

gt = G(i1, ,it). (1.14)

In the terminology of Gold (1965), G determines a limiting recursive
functional whose domain is information sequences. It is shown in
Theorem 5 of that reference that any limiting recursive functional can
be defined by means of a primitive recursive guessing function. It will be
assumed that G is primitive recursive. It will also be assumed that L
is recursive since, otherwise, L cannot be tester identiﬁed and the conclu—
sion of the theorem is immediate. Let f(x)‘bo a primitive recursive func—
tion with a range equal to L.

A primitive recursive text it will be constructed which contradicts the
assumption that G is a suitable guessing rule. A function X t will also be
deﬁned. Let P t and Q; signify the following predicates:

Pt E ”<th = 11]" V[f(Xt) = it] (1.15)
Qt (32/ § t){T[gt,f(X,), yl & WW) = 0]}, (1-16)

where T(a, x, g) is the primitive recursive predicate which says that the
Turing machine with Godel number a, if presented with x as an input,
Will stop after performing the computation with Godel number 3/; and
U ( 11/) is a primitive recursive function such that, if y is the Godel number,
Of a Turing machine computation, then U ( y) is the number it produces
at its end.

it and X t are simultaneously deﬁned by course—of—values recursion‘as
follmm
is.

Ill

XI = 1 (1.17)
a = f(1) (1.18)

% ----- new page ---
472 GOLD

X,“ = Xt + 1 if P, (1.19)
= Xi if —.P, . (1.20)
it” = f(Xt) if —:Pt and Q, (1.21)
= it otherwise. (1.22)

The idea behind the construction is this: it is designed to generate L,
but very slowly. After a ﬁnite number of elements of L have been
generated, x1 , - ' - , x,_1 , if it repeats ac, long enough the guessing pro.
cedure will have to guess a decision procedure for the set {301 , - - - , 30,},
which must reject it.“ . As soon as g; is known to reject xr+1 , it starts
producing it. Q implies Zg,(x,+1) = 0, where er = f( X t). The details
follow.

Case I. —1 Pt holds for only a ﬁnite number of t. It will be shown that this
implies that Rng( f) is ﬁnite. Let Pt hold for all t g (1. Then, by in-
duction,

[by (1.19)] t g a => X. = X... + (t — a)
[by (1.22)] it = 2;,
[by (115)] 11th E ”I , :78}-
Thus,
n 3 X0: => f(n) E {t}, ,ia}.

Case II. -—.Pt holds inﬁnitely often, but Q; holds for only a ﬁnite
number of t. It will be shown that Rng(z’t) is ﬁnite, but if gt-é a, then there
is an x Q Rng(i,) such that Za(x) 7f 0. Choose a large enough so that
ﬁQt holds for all t g a. Induction on Eq. (1.22) gives

it = in, for all t g a. (1.23)
Thus,
Rng(7’l) = {7:17 H ' )ial'
Let )6 be large enough that
>
B = a (1.24)

gt=a forall tgﬁ
ﬁPﬁ holds. (125)

% ----- new page ---
LANGUAGE IDENTIFICATION IN THE LIMIT 473

Induction on Eqs. (1.20) and (I.15)‘gives, using (1.25) and (1.23),
X, = X5 forall If; 6
f(X;3) E {in ,ial-
Let x = f(Xg). Now (1.16). (1.24), and (1.26) give
ﬁC-ly s t){T(a,x,y) & U(y) = 0} for all t g 5.
Thus,

(1.26)

Za(x) 7f 0.

Case III. Q, holds inﬁnitely often. It will be shown that Rng(2't) =
Rng(f); but if gt ——> a, then there is an x such that x E Rng(f) and
Za(;v) = 0. Let a satisfy

gt = a forall t: oz.
Let 6 g a such that (2;; holds. Set

56 = f (X5)-
Then Q3 gives Za(x) = 0.
Raga.) = Rng(f) will be shown by‘contradiction. We know, by
(1.18) and (1.21), that

f(1) E Rngﬁt) C EMU)-

Let x be the lowest number such that

f(X) é Rngﬂz)
(1.19) and (1.20) show that X t is monotone increasing and either takes
on all values, or is ultimately constant.

Case IIIA. X, = X0, for allt g (1. Then (1.19) and (1.20) show that
NP; holds for t g at. By the assumption in Case 111, there is a B > a
such that —.P5 and Q5 . (1.21) shows that ig+1 = f(X3). Then P3“ holds,
since X 5+1 = X5 by the assumption of Case 111A.

h Case NIB. (1 is the last t such that X; = X. Then, by (1.19), Pa must
Old, i.e.,

f<Xa) E Rng(z’.). Q.E.D.
APPENDIX 11
DEFINITIONS OF SOME OF THE TECHNICAL TERMINOLOGY

Turing machines are a special class of algorithms which are precisely
deﬁned, so that they can be investigated mathematically, but are be-

% ----- new page ---
474 GOLD

lieved to be perfectly general in the following sense. Given any compu-
tational rule which we would intuitively accept as an effectively deﬁned
algorithm, the function deﬁned by this algorithm is also deﬁned by some
Turing machine. The recursive functions are those functions which can
be deﬁned by Turing machines. The inputs to a Turing machine may be
considered to be either strings or positive integers, and the same is true
of its outputs.

The primitive recursive algorithms are a special class of algorithms which
are not general in the sense of Turing machines, but are general enough
to include all algorithms ordinarily constructed. Primitive recursive
functions are functions which can be deﬁned by primitive recursive
algorithms;

A decision procedure for a language L is an algorithm deﬁned on strings
such that the result of using the algorithm is 1 or 0, depending on whether
the string it starts with is an element of L or not. A generator for L is an
algorithm which takes positive integers into strings such that the range of
the function it determines is exactly L.

L is called recursively enumerable (re) if there is a generator for it,
recursive if there is a decision procedure for it, primitive recursive if there
is a primitive recursive decision procedure for it, and regular if there is a
decision procedure for it which can be computed by a ﬁnite state
automaton.

